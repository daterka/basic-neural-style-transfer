{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer stylu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Celem projektu jest stworzenie algorytmu realizującego problem przeniesienia stylu między dwoma obrazami cyfrowymi z wykorzystaniem sieci głębokich."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# required libraries \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = (10,10)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import time\n",
    "import functools\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.python.keras.preprocessing import image as kp_image\n",
    "from tensorflow.python.keras import models \n",
    "from tensorflow.python.keras import losses\n",
    "from tensorflow.python.keras import layers\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "import IPython.display\n",
    "\n",
    "\n",
    "import os\n",
    "import gc\n",
    "\n",
    "from log import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables \n",
    "# input/output images\n",
    "input_dir = './images/input/'\n",
    "style_dir = input_dir + 'style/'\n",
    "content_dir = input_dir + 'content/'\n",
    "\n",
    "output_dir = './images/output/'\n",
    "output_intel_dir = './images/output-intel/'\n",
    "output_endless_dir = './images/output-endless/'\n",
    "\n",
    "output_format = '.png'\n",
    "\n",
    "content_path = ''\n",
    "style_path = ''\n",
    "\n",
    "# number of iterations\n",
    "iter_num = 1000\n",
    "\n",
    "# image and loss vals logging interval (between iterations)\n",
    "log_int = iter_num/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./images/input/style/\n",
      "./images/input/content/\n",
      "./images/output/\n"
     ]
    }
   ],
   "source": [
    "print(style_dir)\n",
    "print(content_dir)\n",
    "print(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Wczytywanie oraz wizualizacja danych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wczytywanie obrazu z dysku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load image from disc and perform preprocessing\n",
    "# return image as 4dim array of pixels (3 color levels)\n",
    "def load_img(path_to_img):\n",
    "    max_dim = 512\n",
    "    img = Image.open(path_to_img)\n",
    "    long = max(img.size)\n",
    "    scale = max_dim/long\n",
    "    img = img.resize((round(img.size[0]*scale), round(img.size[1]*scale)), Image.ANTIALIAS)\n",
    "\n",
    "    img = kp_image.img_to_array(img)\n",
    "\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wyświetlanie obrazu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print image (array of pixels form)\n",
    "def imshow(img, title=None):\n",
    "    # Remove the batch dimension\n",
    "    out = np.squeeze(img, axis=0)\n",
    "    # Normalize for display \n",
    "    out = out.astype('uint8')\n",
    "    plt.imshow(out)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.imshow(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. Wstępne przygotowywanie danych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wczytanie ze wstępnym przetworzeniem pod kątem modelu sieci VGG19.\n",
    "* Zmiana kolejności warst z RGB na BGR.\n",
    "* Normalizacja pikseli kazdej warstwy poprzez odjęcie od wartości pikseli danej warstwy, średniej wartości pikseli dla tej warstwy w zbiorze treningowym sieci VGG19."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and perform preprocessing according to vgg19 requirements\n",
    "# return preprocessed image (array of pixels format)\n",
    "def load_and_process_img(path_to_img):\n",
    "    img = load_img(path_to_img)\n",
    "    img = tf.keras.applications.vgg19.preprocess_input(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Denormalizacja przetworzobego obrazu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# denormalize image (array of pixels form)\n",
    "# return image as array of pixels\n",
    "def deprocess_img(processed_img):\n",
    "    x = processed_img.copy()\n",
    "    if len(x.shape) == 4:\n",
    "        x = np.squeeze(x, 0)\n",
    "    assert len(x.shape) == 3, (\"Input to deprocess image must be an image of \"\n",
    "                             \"dimension [1, height, width, channel] or [height, width, channel]\")\n",
    "    if len(x.shape) != 3:\n",
    "        raise ValueError(\"Invalid input to deprocessing image\")\n",
    "\n",
    "    # perform the inverse of the preprocessing step\n",
    "    x[:, :, 0] += 103.939\n",
    "    x[:, :, 1] += 116.779\n",
    "    x[:, :, 2] += 123.68\n",
    "    x = x[:, :, ::-1]\n",
    "\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wyznaczenie warst pośrednich modelu VGG19, które posłużą do budowy nowego modelu realizującego transfer stylu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Content layer where will pull our feature maps\n",
    "content_layers = ['block5_conv2'] \n",
    "\n",
    "# Style layer we are interested in\n",
    "style_layers = ['block1_conv1',\n",
    "                'block2_conv1',\n",
    "                'block3_conv1', \n",
    "                'block4_conv1', \n",
    "                'block5_conv1'\n",
    "               ]\n",
    "\n",
    "num_content_layers = len(content_layers)\n",
    "num_style_layers = len(style_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III. Zbudowanie nowego modelu realizującego transfer stylu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load pretrained vgg model, pull out activation layers responsible for feature detection, create new model\n",
    "# return new model based on pulled out vgg19 layers\n",
    "def get_model():\n",
    "    # Load VGG, pretrained model\n",
    "    vgg = tf.keras.applications.vgg19.VGG19(include_top=False, weights='imagenet')\n",
    "    vgg.trainable = False\n",
    "    # Get output layers corresponding to style and content layers \n",
    "    style_outputs = [vgg.get_layer(name).output for name in style_layers]\n",
    "    content_outputs = [vgg.get_layer(name).output for name in content_layers]\n",
    "    model_outputs = style_outputs + content_outputs\n",
    "    # Build model \n",
    "    return models.Model(vgg.input, model_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV. Funkcje strat (kosztu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funckje odpowiadające za określenie dystansu określającego stopień różności dwóch obrazów w postaci tablicy pikseli."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Content Loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# determine content loss value\n",
    "# return loss value for content image and target image\n",
    "def get_content_loss(base_content, target):\n",
    "    # return mean of squared difference between output array of signals from model\n",
    "    return tf.reduce_mean(tf.square(base_content - target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Style Loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "def gram_matrix(input_tensor):\n",
    "    # We make the image channels first \n",
    "    channels = int(input_tensor.shape[-1])\n",
    "    a = tf.reshape(input_tensor, [-1, channels])\n",
    "    n = tf.shape(a)[0]\n",
    "    gram = tf.matmul(a, a, transpose_a=True)\n",
    "    return gram / tf.cast(n, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine style loss value\n",
    "# return loss value for style image and target image\n",
    "def get_style_loss(base_style, gram_target):\n",
    "    height, width, channels = base_style.get_shape().as_list()\n",
    "    gram_style = gram_matrix(base_style)\n",
    "    # return mean of squared difference between output 3darray of signals from model\n",
    "    return tf.reduce_mean(tf.square(gram_style - gram_target))# / (4. * (channels ** 2) * (width * height) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V. Optymalizacja modelu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pozyskanie map cech dla obrazów content_image oraz style_image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load style and content image, builds model based on them, retrieve feature maps and list them\n",
    "# returns lists of features for style and content images\n",
    "def get_feature_representations(model, content_path, style_path):\n",
    "    # Load our images in \n",
    "    content_image = load_and_process_img(content_path)\n",
    "    style_image = load_and_process_img(style_path)\n",
    "\n",
    "    # batch compute content and style features\n",
    "    style_outputs = model(style_image)\n",
    "    content_outputs = model(content_image)\n",
    "\n",
    "    # Get the style and content feature representations from our model  \n",
    "    style_features = [style_layer[0] for style_layer in style_outputs[:num_style_layers]]\n",
    "    content_features = [content_layer[0] for content_layer in content_outputs[num_style_layers:]]\n",
    "    return style_features, content_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Określenie w jakim stopniu obraz wyjściowy (target) różni sie od obrazów content_image oraz style_image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute style and content loss values for provided feature maps\n",
    "# return total loss, style loss and content loss\n",
    "def compute_loss(model, loss_weights, init_image, gram_style_features, content_features):\n",
    "    style_weight, content_weight = loss_weights\n",
    "\n",
    "    # Feed our init image through our model.\n",
    "    model_outputs = model(init_image)\n",
    "\n",
    "    style_output_features = model_outputs[:num_style_layers]\n",
    "    content_output_features = model_outputs[num_style_layers:]\n",
    "\n",
    "    style_score = 0\n",
    "    content_score = 0\n",
    "\n",
    "    # Accumulate style losses from all layers\n",
    "    # Here, we equally weight each contribution of each loss layer\n",
    "    weight_per_style_layer = 1.0 / float(num_style_layers)\n",
    "    for target_style, comb_style in zip(gram_style_features, style_output_features):\n",
    "        style_score += weight_per_style_layer * get_style_loss(comb_style[0], target_style)\n",
    "\n",
    "    # Accumulate content losses from all layers \n",
    "    weight_per_content_layer = 1.0 / float(num_content_layers)\n",
    "    for target_content, comb_content in zip(content_features, content_output_features):\n",
    "        content_score += weight_per_content_layer* get_content_loss(comb_content[0], target_content)\n",
    "\n",
    "    style_score *= style_weight\n",
    "    content_score *= content_weight\n",
    "\n",
    "    # Get total loss\n",
    "    loss = style_score + content_score \n",
    "    return loss, style_score, content_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wyliczenie gradientów dla obrazu wyjściowego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# compute the gradiends\n",
    "# return TODO\n",
    "def compute_grads(cfg):\n",
    "    with tf.GradientTape() as tape: \n",
    "        all_loss = compute_loss(**cfg)\n",
    "    # Compute gradients wrt input image\n",
    "    total_loss = all_loss[0]\n",
    "    return tape.gradient(total_loss, cfg['init_image']), all_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcja optymalizująca model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "# performs style transfer updating target images according to loss values of loaded content and style images\n",
    "# prints updated target image and loss values for selected interval\n",
    "# return image with best loss and best loss value\n",
    "def run_style_transfer(target_dir, content_path, style_path, num_iterations=1000, \n",
    "                       content_weight=1e3, style_weight=1e-2, log_interval = None): \n",
    "    # We don't need to (or want to) train any layers of our model, so we set their\n",
    "    # trainable to false. \n",
    "    model = get_model() \n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Get the style and content feature representations (from our specified intermediate layers) \n",
    "    style_features, content_features = get_feature_representations(model, content_path, style_path)\n",
    "    gram_style_features = [gram_matrix(style_feature) for style_feature in style_features]\n",
    "\n",
    "    # Set initial image\n",
    "    init_image = load_and_process_img(content_path)\n",
    "    init_image = tf.Variable(init_image, dtype=tf.float32)\n",
    "    \n",
    "    # Create optimizer\n",
    "    opt = tf.optimizers.Adam(learning_rate=5, beta_1=0.99, epsilon=1e-1)\n",
    "\n",
    "    # For displaying intermediate images \n",
    "    iter_count = 1\n",
    "\n",
    "    # Store best result\n",
    "    best_loss, best_img = float('inf'), None\n",
    "\n",
    "    # Create config \n",
    "    loss_weights = (style_weight, content_weight)\n",
    "    cfg = {\n",
    "    'model': model,\n",
    "    'loss_weights': loss_weights,\n",
    "    'init_image': init_image,\n",
    "    'gram_style_features': gram_style_features,\n",
    "    'content_features': content_features\n",
    "    }\n",
    "    \n",
    "    # For displaying\n",
    "    num_rows = 2\n",
    "    num_cols = 5\n",
    "\n",
    "    if log_interval is None:\n",
    "        display_interval = num_iterations/(num_rows*num_cols)\n",
    "        #display_interval = 100\n",
    "    else:\n",
    "        display_interval = log_interval\n",
    "        \n",
    "    global_start = time.time()\n",
    "\n",
    "    norm_means = np.array([103.939, 116.779, 123.68])\n",
    "    min_vals = -norm_means\n",
    "    max_vals = 255 - norm_means   \n",
    "\n",
    "    imgs = []\n",
    "    sum_time = 0\n",
    "    sum_time_all = 0\n",
    "    \n",
    "    ## logger\n",
    "    \n",
    "    log = logger(target_dir, content_path, style_path)\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        start_time = time.time()\n",
    "        grads, all_loss = compute_grads(cfg)\n",
    "        loss, style_score, content_score = all_loss\n",
    "        opt.apply_gradients([(grads, init_image)])\n",
    "        clipped = tf.clip_by_value(init_image, min_vals, max_vals)\n",
    "        init_image.assign(clipped)\n",
    "        end_time = time.time()\n",
    "        sum_time = sum_time + end_time - start_time\n",
    "        sum_time_all = sum_time_all + end_time - start_time\n",
    "        \n",
    "        # log loss vals nad iter duration\n",
    "        log.iteration_data(i, loss, content_score, style_score, end_time-start_time)\n",
    "\n",
    "        if loss < best_loss:\n",
    "            # Update best loss and best image from total loss. \n",
    "            best_loss = loss\n",
    "            best_img = deprocess_img(init_image.numpy())\n",
    "\n",
    "        if (i+1) % display_interval == 0:\n",
    "            plot_img = init_image.numpy()\n",
    "            plot_img = deprocess_img(plot_img)\n",
    "            imgs.append(plot_img)\n",
    "            IPython.display.display_png(Image.fromarray(plot_img))\n",
    "            \n",
    "            print('Iteration: {}'.format(i))        \n",
    "            print('Total loss: {:.4e}, ' \n",
    "                'style loss: {:.4e}, '\n",
    "                'content loss: {:.4e}, '\n",
    "                'avg iteration time: {:.4f}s'.format(loss, style_score, content_score, sum_time/display_interval))\n",
    "            \n",
    "            sum_time = 0\n",
    "            \n",
    "            log.save_image_jpg(iteration_number=i, image=Image.fromarray(plot_img))\n",
    "\n",
    "    print('Total time: {:.4f}s'.format(time.time() - global_start))\n",
    "    print('Iteration avarage time: {:.4f}s'.format(sum_time_all/num_iterations))\n",
    "    \n",
    "    log.save_data_to_csv()\n",
    "    log.draw_plots()\n",
    "    log.save_image_jpg(image=Image.fromarray(best_img))\n",
    "    \n",
    "    del log\n",
    "    \n",
    "    plt.figure(figsize=(14,4))\n",
    "    for i,img in enumerate(imgs):\n",
    "        plt.subplot(num_rows,num_cols,i+1)\n",
    "        plt.imshow(img)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        \n",
    "    del imgs\n",
    "        \n",
    "    return best_img, best_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VI. Przeprowadzenie transferu stylu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wyświetlenie obrazów reprezentujących styl oraz kopozycję."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# print best target, content and style images\n",
    "def show_results(best_img, content_path, style_path, show_large_final=True):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    content = load_img(content_path) \n",
    "    style = load_img(style_path)\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    imshow(content, 'Content Image')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    imshow(style, 'Style Image')\n",
    "\n",
    "    if show_large_final: \n",
    "        plt.figure(figsize=(10, 10))\n",
    "\n",
    "        plt.imshow(best_img)\n",
    "        plt.title('Output Image')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uruchomienie algorytmu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_content_and_style_img(content_path=None, style_path=None):  \n",
    "    # content and style files locations\n",
    "    content_path = 'img_dir/oryginal.jpg' if content_path is None else content_path\n",
    "    style_path = 'img_dir/art.jpg' if style_path is None else style_path\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "\n",
    "    # load images\n",
    "    content = load_img(content_path).astype('uint8')\n",
    "    style = load_img(style_path).astype('uint8')\n",
    "\n",
    "    # print images\n",
    "    print(\"Imput images\")\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    imshow(content, 'Content Image')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    imshow(style, 'Style Image')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_transfer(target_dir=output_dir, content_path=content_dir+'turtle.jpg', style_path=style_dir+'ukiyo-e.jpg'):\n",
    "    #display_content_and_style_img(content_path, style_path)\n",
    "\n",
    "    # start transfer\n",
    "    print(\"Processing images\" + target_dir)\n",
    "    best, best_loss = run_style_transfer(target_dir, content_path, style_path, num_iterations=iter_num, log_interval=100)\n",
    "\n",
    "    Image.fromarray(best)\n",
    "\n",
    "    # show results\n",
    "    print(\"Result:\")\n",
    "    show_results(best, content_path, style_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing images./images/output-test/afgan-girl-photo_van-gogh\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# main loop for detecting content and style images and iterate through all combinations running style transfer\n",
    "for content in os.listdir(content_dir):\n",
    "    for style in os.listdir(style_dir):\n",
    "        try:\n",
    "            target_dir = './images/output-test/'+content.split('.')[0]+'_'+style.split('.')[0]\n",
    "            run_transfer(target_dir, content_dir+content, style_dir+style)\n",
    "            gc.collect()\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
